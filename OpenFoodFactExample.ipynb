{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "We demo a text classification approach based on an open dataset from https://world.openfoodfacts.org/. The goal of our talk is to categorize food items with various tags, where a particular food item is defined by a product's name, a generic name as well as a brand. For classification, we use facebooks NLP model fasttext, which provides a text classification model based on word embeddings as well as character n-gram embeddings. In a first experiment, we only use a single tag and remove additional ones from each data point. In this case, the evaluation is straight forward. However, since some classes are more closely related than others, we don't want to evaluate predictions in a binary manner as one would typically do. To this end, we implement a similarity concept and a multilabel classification approach. Additionally, we present some applications of a standardized food catalog, for instance search and recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fasttext import *\n",
    "%matplotlib inline\n",
    "import evaluation_metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import scipy.spatial.distance as sd\n",
    "import sklearn.metrics.pairwise as pw\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FASTTEXT_HOME=\"/Users/evelyn.trautmann/repos/fasttext3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "The following classification is based on an open dataset from https://world.openfoodfacts.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_name            324820\n",
       "generic_name             83152\n",
       "brands                  269465\n",
       "categories              329303\n",
       "categories_tags         329303\n",
       "origins                  47351\n",
       "manufacturing_places     73767\n",
       "labels                  118779\n",
       "emb_codes                52104\n",
       "countries               329099\n",
       "main_category           329297\n",
       "en_tags                 329303\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/foodcategories_single_label.csv.zip\", sep = \"\\x01\", compression=\"zip\")\n",
    "df.en_tags = df.en_tags.apply(eval)\n",
    "df = df[df.en_tags.str.len()>0]\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to classify tags based on product name, generic name and brand. In the first dataset we have a single tag assigned to each data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1    329303\n",
       " Name: en_tags, dtype: int64, '87 labels ')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.en_tags.str.len().value_counts(), \"%i labels \"%len(set(np.concatenate(df.en_tags.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#generate features\n",
    "feature_cols = ['product_name', 'generic_name', 'brands']\n",
    "assert(df[df.en_tags.str.len()==0].shape[0]==0)\n",
    "X = df[feature_cols].fillna(\"\").apply(lambda x: \" \".join(x), axis = 1)\n",
    "y = df.en_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess and split train and test date\n",
    "X = X.str.lower().apply(lambda x: re.sub(r'[^\\w\\s]','',x))\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.25, random_state=13)\n",
    "\n",
    "dftrain = y_train.apply(lambda x: \" \".join([\"__label__\" + y\n",
    "                    for y in x])) + \" \" + X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((65861,), (65861,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain_emb = y_train.apply(lambda x: \" \".join(x)) + \" \" + X_train\n",
    "\n",
    "\n",
    "dftest = y_test.apply(lambda x: \" \".join([\"__label__\" + y\n",
    "                    for y in x])) + \" \" + X_test\n",
    "dfvalid = y_valid.apply(lambda x: \" \".join([\"__label__\" + y\n",
    "                    for y in x])) + \" \" + X_valid\n",
    "dftest.shape, dfvalid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain.to_csv(\n",
    "    \"train.csv\", index = False, sep=\";\")\n",
    "dftest.to_csv(\n",
    "    \"test.csv\", index = False, sep=\";\")\n",
    "dfvalid.to_csv(\n",
    "    \"valid.csv\", index = False, sep=\";\")\n",
    "dftrain_emb.to_csv(\n",
    "    \"train_emb.csv\", index = False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification we use fasttext, which can be either executed on command line or "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_singlelabel = train_supervised(\"train.csv\",\n",
    "                lr = 0.01,\n",
    "                autotuneValidationFile = \"valid.csv\",\n",
    "                autotuneDuration = 1000)\n",
    "\n",
    "model_singlelabel.save_model(\"model_singlelabel.bin\")\n",
    "# !$FASTTEXT_HOME/fastText/fasttext supervised \\\n",
    "#     -input \"train.csv\" -output model_singlelabel \\\n",
    "#     -autotune-validation \"valid.csv\" -autotune-duration 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_singlelabel = load_model(\"model_singlelabel.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim 43\r\n",
      "ws 5\r\n",
      "epoch 100\r\n",
      "minCount 1\r\n",
      "neg 5\r\n",
      "wordNgrams 3\r\n",
      "loss softmax\r\n",
      "model sup\r\n",
      "bucket 10000000\r\n",
      "minn 0\r\n",
      "maxn 0\r\n",
      "lrUpdateRate 100\r\n",
      "t 0.0001\r\n"
     ]
    }
   ],
   "source": [
    "!$FASTTEXT_HOME/fastText/fasttext dump model_singlelabel.bin args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t65860\r\n",
      "P@1\t0.777\r\n",
      "R@1\t0.777\r\n"
     ]
    }
   ],
   "source": [
    "!$FASTTEXT_HOME/fastText/fasttext test model_singlelabel.bin test.csv 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_emb = train_unsupervised(\"/Users/evelyn.trautmann/projects/openfood/train_emb.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65860, 0.7772547828727604, 0.7772547828727604)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_singlelabel.test(\"test.csv\", k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65861, 0.7778199541458526, 0.7778199541458526)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_singlelabel.test(\"valid.csv\", k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = X_test.to_frame()\n",
    "df_test.columns = [\"feature\"]\n",
    "\n",
    "# determine number of labels\n",
    "df_test = df_test.join(y_test)\n",
    "\n",
    "K = int(df_test.en_tags.str.len().quantile(0.75))\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Label Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"prediction\"] = df_test.feature.apply(lambda x: model_singlelabel.predict(x))\n",
    "\n",
    "df_test[\"label_predicted\"] = df_test.prediction.str[0].str[0].str.replace(\"__label__\",\"\")\n",
    "df_test[\"confidence\"] = df_test.prediction.str[1].str[0]\n",
    "df_test[\"truth\"] = df_test.en_tags.str[0].str.replace(\"__label__\",\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "            alcoholic-beverages       0.79      0.81      0.80      1657\n",
      "                     baby-foods       0.76      0.73      0.74       288\n",
      "                   bee-products       1.00      0.38      0.55         8\n",
      "                          beers       0.00      0.00      0.00         5\n",
      "                      beverages       0.00      0.00      0.00        42\n",
      "             biscuits-and-cakes       0.64      0.50      0.56       569\n",
      "                     breakfasts       0.87      0.87      0.87      3202\n",
      "                          cakes       0.50      0.41      0.45       423\n",
      "                        candies       0.77      0.24      0.36        85\n",
      "                  canned-fishes       0.74      0.77      0.75       503\n",
      "                   canned-foods       0.68      0.21      0.32        72\n",
      "       canned-plant-based-foods       0.54      0.35      0.42        80\n",
      "              carbonated-drinks       0.65      0.59      0.62       216\n",
      "                chicken-breasts       0.00      0.00      0.00         1\n",
      "                       chickens       0.91      0.94      0.92       755\n",
      "                chips-and-fries       0.67      0.27      0.38        37\n",
      "             chocolate-biscuits       0.67      0.54      0.60       508\n",
      "                     chocolates       0.33      0.10      0.16        67\n",
      "                     condiments       0.77      0.56      0.65       302\n",
      "                        dairies       0.68      0.62      0.65       856\n",
      "                       desserts       0.70      0.71      0.71       918\n",
      "            dietary-supplements       0.72      0.74      0.73       352\n",
      "                 dried-products       0.67      0.57      0.62       295\n",
      "               farming-products       0.94      0.95      0.95       293\n",
      "                           fats       0.49      0.23      0.31       364\n",
      "                fermented-foods       0.78      0.77      0.77      2662\n",
      "        fermented-milk-products       0.82      0.83      0.82      2832\n",
      "         fish-and-meat-and-eggs       0.95      0.91      0.93       371\n",
      "                    fresh-foods       0.43      0.27      0.33       375\n",
      "        fresh-plant-based-foods       0.59      0.54      0.56       447\n",
      "                frozen-desserts       0.00      0.00      0.00         2\n",
      "                   frozen-foods       0.73      0.60      0.66       419\n",
      "       frozen-plant-based-foods       0.70      0.63      0.66       395\n",
      "        frozen-ready-made-meals       0.34      0.22      0.27       187\n",
      "             fruits-based-foods       0.79      0.72      0.75        72\n",
      "                      groceries       0.47      0.29      0.36        80\n",
      "                           hams       0.89      0.94      0.91       717\n",
      "                  hot-beverages       0.00      0.00      0.00        25\n",
      "                     ice-creams       0.85      0.82      0.83       671\n",
      "                   legume-seeds       0.81      0.77      0.79       501\n",
      "                        legumes       0.00      0.00      0.00        10\n",
      "     legumes-and-their-products       0.73      0.68      0.70        66\n",
      "                          meals       0.70      0.75      0.72      2238\n",
      "                meals-with-fish       0.85      0.69      0.76       211\n",
      "            meat-based-products       0.80      0.81      0.81      1368\n",
      "                          meats       0.80      0.82      0.81      1034\n",
      "                microwave-meals       0.00      0.00      0.00        58\n",
      "                milk-substitute       0.00      0.00      0.00         6\n",
      "                          milks       0.83      0.84      0.83       833\n",
      "        non-alcoholic-beverages       0.51      0.44      0.47      1225\n",
      "                           nuts       0.88      0.77      0.82       610\n",
      "            olive-tree-products       0.86      0.91      0.88       655\n",
      "                         olives       0.91      0.93      0.92       344\n",
      "                       pastries       0.78      0.71      0.74       479\n",
      "                        pickles       0.86      0.71      0.78       188\n",
      "          plant-based-beverages       0.00      0.00      0.00         2\n",
      "              plant-based-foods       0.78      0.87      0.82     11990\n",
      "plant-based-foods-and-beverages       0.73      0.82      0.77      2775\n",
      "                      poultries       0.91      0.90      0.91       374\n",
      "                 prepared-meats       0.88      0.89      0.88      2114\n",
      "            prepared-vegetables       0.00      0.00      0.00         2\n",
      "             refrigerated-foods       0.00      0.00      0.00        22\n",
      "                         salads       0.00      0.00      0.00        27\n",
      "                   salty-snacks       0.84      0.74      0.79       524\n",
      "                         sauces       0.92      0.94      0.93      2978\n",
      "                       sausages       0.80      0.29      0.42        14\n",
      "                        seafood       0.83      0.84      0.84      1486\n",
      "                  smoked-fishes       0.00      0.00      0.00         8\n",
      "                         snacks       0.79      0.83      0.81      7359\n",
      "                          soups       0.69      0.62      0.65       281\n",
      "                        spreads       0.81      0.70      0.75       737\n",
      "                   sweet-snacks       0.66      0.58      0.62       653\n",
      "            sweetened-beverages       0.61      0.59      0.60      1349\n",
      "                     sweeteners       0.87      0.86      0.87       477\n",
      "                         syrups       0.41      0.24      0.30        66\n",
      "                           teas       0.00      0.00      0.00        10\n",
      "          unsweetened-beverages       0.45      0.35      0.39       985\n",
      "                 vegetable-fats       0.00      0.00      0.00        18\n",
      "         vegetables-based-foods       0.67      0.60      0.63       334\n",
      "                  viennoiseries       0.00      0.00      0.00         1\n",
      "                          wines       0.00      0.00      0.00         1\n",
      "              wines-from-france       0.58      0.45      0.51       295\n",
      "\n",
      "                      micro avg       0.78      0.78      0.78     65861\n",
      "                      macro avg       0.58      0.51      0.53     65861\n",
      "                   weighted avg       0.77      0.78      0.77     65861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(df_test.truth, df_test.label_predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# assertion no empty tags\n",
    "assert(len(df_test.en_tags[df_test.en_tags.str.len()==0])==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cakes                  172\n",
       "snacks                 152\n",
       "biscuits-and-cakes      27\n",
       "desserts                17\n",
       "pastries                15\n",
       "plant-based-foods        9\n",
       "chocolate-biscuits       6\n",
       "ice-creams               4\n",
       "sweet-snacks             4\n",
       "meals                    3\n",
       "breakfasts               2\n",
       "frozen-foods             2\n",
       "dairies                  2\n",
       "sauces                   1\n",
       "meats                    1\n",
       "spreads                  1\n",
       "alcoholic-beverages      1\n",
       "nuts                     1\n",
       "sweetened-beverages      1\n",
       "fruits-based-foods       1\n",
       "fresh-foods              1\n",
       "Name: label_predicted, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = \"cakes\"\n",
    "df_test[df_test.truth==label].label_predicted.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the model is predicting other than the ground truth but still makes reasonable class assignments. To distinguish the reasonable assignments from the actually wrong classifications we introduce similarities between classes to count them into the accurate predicftions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example\n",
    "Consider followin common products\n",
    "chicken, poultries, seafood\n",
    "Given that the first two are pretty similar and the latter very different, a possible similarity matrix S could look like\n",
    "\n",
    "\n",
    "\n",
    "|Labels | chicken | poultries |seafood|\n",
    "|---------|:------------------|:-------------------|:--------------|\n",
    "|chicken | 1 | 0.9 | 0 |\n",
    "| poultries | 0.9 | 1 | 0 |\n",
    "| seafood | 0 | 0 | 1 |\n",
    "\n",
    "\n",
    "If we want to include now similarity into calculation of precision and recall, we have the nominator containing not only\n",
    "\n",
    "Count[ Truth = chicken, Predicted = chicken ]\n",
    "\n",
    "but\n",
    "\n",
    "Count[ Truth = chicken, Predicted = chicken ] * 1 + Count[Predicted  = chicken, Truth = poultries ] * 0.9.\n",
    "\n",
    "Hence diagonal entries of confusion matrix \n",
    "\n",
    "$$ C_{ii} = Count[Truth=i,Predicted=i]$$\n",
    "\n",
    "become \n",
    "\n",
    "$$ C_{ij} = \\sum_j Count[Predicted=i,Truth=j]* S_{ij} $$\n",
    "\n",
    "That means, we count in all similar predictions weighted by degree of similatity.\n",
    "Technically that means we take the diagonal entris of\n",
    "\n",
    "$$\\hat{C}=C∗S\\hat{C} = C * S \\hat{C}=C∗S$$\n",
    "\n",
    "\n",
    "Where * denotes matrix product. Denominator remains the same: Row sum in case of precision, column sum in case of recall. Here we don't weight by similar entries since for denominator only the exact number of True (resp. Predicted ) counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth=[\"truth\"]\n",
    "predictions=[\"label_predicted\"]\n",
    "classes = list(set(np.concatenate(df_test[predictions + truth].apply(tuple).apply(list).values)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute diffecence sets\n",
      "compute intersections\n",
      "determine vectors\n",
      "CPU times: user 3min 38s, sys: 3.56 s, total: 3min 42s\n",
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "%time confusion = evaluation_metrics.get_confusion(df_test, classes, K, truth, predictions)\n",
    "confusion.to_csv(\"confusion_single_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_metrics.get_confusion??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = pd.read_csv(\"confusion_single_label.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plant-based-foods-and-beverages              plant-based-beverages\n",
      "fermented-milk-products                                    dairies\n",
      "plant-based-beverages              plant-based-foods-and-beverages\n",
      "groceries                                                   sauces\n",
      "seafood                                              smoked-fishes\n",
      "vegetables-based-foods                    frozen-plant-based-foods\n",
      "snacks                                                sweet-snacks\n",
      "fresh-plant-based-foods                     vegetables-based-foods\n",
      "canned-fishes                                              seafood\n",
      "pickles                                                     olives\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:56: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Compute word embeddings for each class and pairwise distance\n",
    "# between every two classes. Set all distances that exceed a\n",
    "# pre-defined threshold to null and compute rbf function as similarity.\n",
    "#\n",
    "class_vecs = pd.Series({cl:model_emb.get_sentence_vector(cl) for cl in classes})\n",
    "\n",
    "Dst = class_vecs.apply(lambda x: class_vecs.apply(lambda y: sd.euclidean(x,y)))\n",
    "MAGIC_NUMBER = 0.7\n",
    "mask = Dst > MAGIC_NUMBER\n",
    "Dst[mask]=np.nan\n",
    "# print similar but not identical classes \n",
    "print(Dst.apply(np.argmax)[Dst.max()>0.0].sample(10))\n",
    "\n",
    "S = np.exp(-Dst**2).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pasteurized-cheeses</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.055944</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refrigerated-foods</th>\n",
       "      <td>0.278381</td>\n",
       "      <td>0.134670</td>\n",
       "      <td>0.181526</td>\n",
       "      <td>349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canned-plant-based-foods</th>\n",
       "      <td>0.493671</td>\n",
       "      <td>0.118182</td>\n",
       "      <td>0.190709</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>microwave-meals</th>\n",
       "      <td>0.393443</td>\n",
       "      <td>0.183746</td>\n",
       "      <td>0.250502</td>\n",
       "      <td>283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bee-products</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canned-foods</th>\n",
       "      <td>0.407878</td>\n",
       "      <td>0.357860</td>\n",
       "      <td>0.381235</td>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fats</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.484765</td>\n",
       "      <td>0.408481</td>\n",
       "      <td>361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fresh-foods</th>\n",
       "      <td>0.456874</td>\n",
       "      <td>0.416988</td>\n",
       "      <td>0.436021</td>\n",
       "      <td>777.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fresh-plant-based-foods</th>\n",
       "      <td>0.584229</td>\n",
       "      <td>0.356674</td>\n",
       "      <td>0.442935</td>\n",
       "      <td>457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frozen-ready-made-meals</th>\n",
       "      <td>0.499261</td>\n",
       "      <td>0.426768</td>\n",
       "      <td>0.460177</td>\n",
       "      <td>396.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          precision    recall   f1score  support\n",
       "pasteurized-cheeses        0.363636  0.030303  0.055944    132.0\n",
       "refrigerated-foods         0.278381  0.134670  0.181526    349.0\n",
       "canned-plant-based-foods   0.493671  0.118182  0.190709    110.0\n",
       "microwave-meals            0.393443  0.183746  0.250502    283.0\n",
       "bee-products               1.000000  0.222222  0.363636      9.0\n",
       "canned-foods               0.407878  0.357860  0.381235    299.0\n",
       "fats                       0.352941  0.484765  0.408481    361.0\n",
       "fresh-foods                0.456874  0.416988  0.436021    777.0\n",
       "fresh-plant-based-foods    0.584229  0.356674  0.442935    457.0\n",
       "frozen-ready-made-meals    0.499261  0.426768  0.460177    396.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_report = evaluation_metrics.get_report(confusion, S)\n",
    "df_report.dropna().sort_values(by=\"f1score\", ascending = True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.617111</td>\n",
       "      <td>0.57801</td>\n",
       "      <td>0.596921</td>\n",
       "      <td>65861.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.804638</td>\n",
       "      <td>0.811064</td>\n",
       "      <td>0.807839</td>\n",
       "      <td>65861.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             precision    recall  f1-score  support\n",
       "macro avg     0.617111   0.57801  0.596921  65861.0\n",
       "weighted avg  0.804638  0.811064  0.807839  65861.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics.get_summary(df_report, confusion, S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilabel Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df = pd.read_csv(\"data/foodcategories_3labels.csv.zip\", sep = \"\\x01\", compression=\"zip\")\n",
    "df.en_tags = df.en_tags.apply(eval)\n",
    "df = df[df.en_tags.str.len()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.en_tags\n",
    "feature_cols = ['product_name', 'generic_name', 'brands']\n",
    "assert(df[df.en_tags.str.len()==0].shape[0]==0)\n",
    "X = df[feature_cols].fillna(\"\").apply(lambda x: \" \".join(x), axis = 1)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=17)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.25, random_state=23)\n",
    "\n",
    "dftrain = y_train.apply(lambda x: \" \".join([\"__label__\" + y\n",
    "                    for y in x])) + \" \" + X_train\n",
    "dftest = y_test.apply(lambda x: \" \".join([\"__label__\" + y\n",
    "                    for y in x])) + \" \" + X_test\n",
    "dfvalid = y_valid.apply(lambda x: \" \".join([\"__label__\" + y\n",
    "                    for y in x])) + \" \" + X_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain.to_csv(\n",
    "    \"train_3label.csv\", index = False, sep=\";\")\n",
    "dftest.to_csv(\n",
    "    \"test3label.csv\", index = False, sep=\";\")\n",
    "dfvalid.to_csv(\n",
    "    \"valid3label.csv\", index = False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3label = train_supervised(\"train_3label.csv\",\n",
    "                lr = 0.01,\n",
    "                autotunePredictions = 3,\n",
    "                autotuneValidationFile = \"valid3label.csv\",\n",
    "                autotuneDuration = 1000)\n",
    "model_3label.save_model(\"model_3label.bin\")\n",
    "\n",
    "# !FASTTEXT_HOME/fastText/fasttext supervised \\\n",
    "#     -input \"train_3label.csv\" -output model_3label \\\n",
    "#     -autotune-validation \"test3label.csv\" -autotune-duration 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_3label = load_model(\"model_3label.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65844, 0.7418443593949334, 0.8265021235314356)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3label.test(\"test3label.csv\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let \\{$T_1^{(1)}, ...,T_M^{(1)}$\\},...,\\{$T_1^{(N)}, ...,T_M^{(N)}$\\} be our ground truth, \n",
    "\\{$P_1^{(1)}, ...,P_M^{(1)}$\\},...,\\{$P_1^{(N)}, ...,P_M^{(N)}$\\} the prediction.\n",
    "\n",
    "on diagonal we count the events of truth matching prediction\n",
    "\n",
    "$\\sum_{i=1}^N |\\{T_1^{(i)}, ...,T_M^{(i)}\\}\\cap \\{P_1^{(i)}, ...,P_M^{(i)}\\}|$\n",
    "\n",
    "so for each diagonal entry we count over all data points (N) and all predictions (M) the total amount when truth is matching prediction.\n",
    "\n",
    "$C_{kk} =\\sum_{i=1}^N \\sum_{m=1}^M \\chi{1}\\{T_m^{(i)}=k,P_m^{(i)}=k\\} $\n",
    "\n",
    "in contrast on off-diagonal we count all events where truth was not covered by prediction.\n",
    "For the off-diagonal we take only the difference sets into account. If truth for data point i was for example {fish, curry, rice-dish} and prediction was {fish, curry, soup }, we only count \n",
    "$T^i$ = {rice_dish} and $P^i$ = {soup} for the off-daigonal. Formally we do the following transformation:\n",
    "\n",
    "$\\{\\tilde{T}_m^{(i)}\\}_{q=1,..M1} = \\{T_m^{(i)}\\}_{m=1,..M}\\setminus \\{P_m^{(i)}\\}_{m=1,..M}$ \n",
    "\n",
    "$\\{\\tilde{P}_m^{(i)}\\}_{p=1,..M2} = \\{P_m^{(i)}\\}_{m=1,..M}\\setminus \\{T_m^{(i)}\\}_{m=1,..M}$\n",
    "\n",
    "Eventually we count all events of the ground truth that were not captured in predictions, which results in\n",
    "\n",
    "$C_{kl} =\\sum_{i=1}^N \\sum_{m1=1}^{M1} \\sum_{m2=1}^{M2}\n",
    "\\frac{1}{M1}\\chi{1}\\{\\tilde{T}_{m1}^{(i)}=k,\\tilde{P}_{m2}^{(i)}=l\\} $\n",
    "\n",
    "Once we have computed a multi-class - multi-label confusion matrix the classification report is straight forward.\n",
    "\n",
    "Precision for class k is computed as\n",
    "\n",
    "$Pr_k=\\frac{C_{kk}}{\\sum_j C_{kj}}$\n",
    "\n",
    "and Recall\n",
    "\n",
    "$R_k=\\frac{C_{kk}}{\\sum_j C_{jk}}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = X_test.to_frame()\n",
    "df_test.columns = [\"feature\"]\n",
    "\n",
    "# determine number of labels\n",
    "df_test = df_test.join(y_test)\n",
    "\n",
    "K = int(df_test.en_tags.str.len().quantile(0.75))\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"prediction\"] = df_test.feature.apply(lambda x: model_3label.predict(x, k=K))\n",
    "\n",
    "for k in range(K):\n",
    "    df_test[\"label_predicted%i\" %k] = df_test.prediction.str[0].str[k].str.replace(\"__label__\",\"\")\n",
    "    df_test[\"confidence%i\" %k] = df_test.prediction.str[1].str[k]\n",
    "    df_test[\"truth%i\" %k] = df_test.en_tags.str[k].str.replace(\"__label__\",\"\")\n",
    "\n",
    "\n",
    "truth = list()\n",
    "predictions = list()\n",
    "for k in range(int(K)):\n",
    "    truth.append(\"truth%i\" %k)\n",
    "    predictions.append(\"label_predicted%i\" %k)\n",
    "classes = list(set(np.concatenate(df_test[predictions + truth].apply(tuple).apply(list).values)))\n",
    "classes.remove(\"nan\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute diffecence sets\n",
      "compute intersections\n",
      "determine vectors\n",
      "CPU times: user 3min 56s, sys: 4.25 s, total: 4min 1s\n",
      "Wall time: 4min\n"
     ]
    }
   ],
   "source": [
    "%time confusion = evaluation_metrics.get_confusion(df_test, classes, K, truth, predictions)\n",
    "\n",
    "confusion.to_csv(\"confusion_3_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = pd.read_csv(\"confusion_3_label.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cooked-pressed-cheeses</th>\n",
       "      <td>0.969397</td>\n",
       "      <td>0.944737</td>\n",
       "      <td>0.956908</td>\n",
       "      <td>380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mustards</th>\n",
       "      <td>0.979548</td>\n",
       "      <td>0.930470</td>\n",
       "      <td>0.954379</td>\n",
       "      <td>489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prepared-meats</th>\n",
       "      <td>0.941215</td>\n",
       "      <td>0.946119</td>\n",
       "      <td>0.943661</td>\n",
       "      <td>3582.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hams</th>\n",
       "      <td>0.928870</td>\n",
       "      <td>0.956463</td>\n",
       "      <td>0.942465</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>honeys</th>\n",
       "      <td>0.920911</td>\n",
       "      <td>0.957540</td>\n",
       "      <td>0.938868</td>\n",
       "      <td>683.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fish-and-meat-and-eggs</th>\n",
       "      <td>0.940222</td>\n",
       "      <td>0.929114</td>\n",
       "      <td>0.934635</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fermented-milk-products</th>\n",
       "      <td>0.930561</td>\n",
       "      <td>0.936394</td>\n",
       "      <td>0.933468</td>\n",
       "      <td>5424.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poultries</th>\n",
       "      <td>0.926476</td>\n",
       "      <td>0.932216</td>\n",
       "      <td>0.929337</td>\n",
       "      <td>1372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sauces</th>\n",
       "      <td>0.917505</td>\n",
       "      <td>0.932817</td>\n",
       "      <td>0.925097</td>\n",
       "      <td>3096.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olive-tree-products</th>\n",
       "      <td>0.933401</td>\n",
       "      <td>0.916168</td>\n",
       "      <td>0.924704</td>\n",
       "      <td>668.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         precision    recall   f1score  support\n",
       "cooked-pressed-cheeses    0.969397  0.944737  0.956908    380.0\n",
       "mustards                  0.979548  0.930470  0.954379    489.0\n",
       "prepared-meats            0.941215  0.946119  0.943661   3582.0\n",
       "hams                      0.928870  0.956463  0.942465    735.0\n",
       "honeys                    0.920911  0.957540  0.938868    683.0\n",
       "fish-and-meat-and-eggs    0.940222  0.929114  0.934635    395.0\n",
       "fermented-milk-products   0.930561  0.936394  0.933468   5424.0\n",
       "poultries                 0.926476  0.932216  0.929337   1372.0\n",
       "sauces                    0.917505  0.932817  0.925097   3096.0\n",
       "olive-tree-products       0.933401  0.916168  0.924704    668.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report = evaluation_metrics.get_report(confusion)\n",
    "df_report.dropna().sort_values(by=\"f1score\", ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.715004</td>\n",
       "      <td>0.655128</td>\n",
       "      <td>0.683758</td>\n",
       "      <td>177565.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.822256</td>\n",
       "      <td>0.8263</td>\n",
       "      <td>0.824273</td>\n",
       "      <td>177565.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             precision    recall  f1-score   support\n",
       "macro avg     0.715004  0.655128  0.683758  177565.0\n",
       "weighted avg  0.822256    0.8263  0.824273  177565.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics.get_summary(df_report, confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Multilabel Classification with Near Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:56: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "plant-based-foods-and-beverages                   plant-based-foods\n",
       "wines                                             wines-from-france\n",
       "frozen-desserts                                          ice-creams\n",
       "artificially-sweetened-beverages                sweetened-beverages\n",
       "milk-chocolates                                          chocolates\n",
       "fermented-milk-products                             fermented-foods\n",
       "teas                                                  hot-beverages\n",
       "pastas                                                    dry-pasta\n",
       "dried-plant-based-foods                    canned-plant-based-foods\n",
       "fruit-yogurts                                               yogurts\n",
       "groceries                                                    sauces\n",
       "dried-products-to-be-rehydrated                      dried-products\n",
       "wines-from-france                                             wines\n",
       "fermented-foods                             fermented-milk-products\n",
       "dry-pasta                                                    pastas\n",
       "non-alcoholic-beverages                       unsweetened-beverages\n",
       "seafood                                                      fishes\n",
       "hot-beverages                                                  teas\n",
       "sweetened-beverages                           unsweetened-beverages\n",
       "chickens                                                  poultries\n",
       "sauces                                                    groceries\n",
       "fishes                                                      seafood\n",
       "unsweetened-beverages                           sweetened-beverages\n",
       "dried-products                      dried-products-to-be-rehydrated\n",
       "chocolates                                          milk-chocolates\n",
       "plant-based-beverages                         fruit-based-beverages\n",
       "chicken-breasts                                            chickens\n",
       "poultries                                                  chickens\n",
       "ice-creams                                          frozen-desserts\n",
       "plant-based-foods                   plant-based-foods-and-beverages\n",
       "fruit-based-beverages                         plant-based-beverages\n",
       "canned-plant-based-foods                    dried-plant-based-foods\n",
       "yogurts                                               fruit-yogurts\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_vecs = pd.Series({cl:model_emb.get_sentence_vector(cl) for cl in classes})\n",
    "\n",
    "Dst = class_vecs.apply(lambda x: class_vecs.apply(lambda y: sd.euclidean(x,y)))\n",
    "\n",
    "mask = Dst > 0.5\n",
    "Dst[mask]=np.nan\n",
    "# show entries with highes distance <= 0.5 for each class\n",
    "Dst.apply(np.argmax)[Dst.max()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cooked-pressed-cheeses</th>\n",
       "      <td>0.969397</td>\n",
       "      <td>0.944737</td>\n",
       "      <td>0.956908</td>\n",
       "      <td>380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mustards</th>\n",
       "      <td>0.979548</td>\n",
       "      <td>0.930470</td>\n",
       "      <td>0.954379</td>\n",
       "      <td>489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prepared-meats</th>\n",
       "      <td>0.941215</td>\n",
       "      <td>0.946119</td>\n",
       "      <td>0.943661</td>\n",
       "      <td>3582.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hams</th>\n",
       "      <td>0.928870</td>\n",
       "      <td>0.956463</td>\n",
       "      <td>0.942465</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>honeys</th>\n",
       "      <td>0.920911</td>\n",
       "      <td>0.957540</td>\n",
       "      <td>0.938868</td>\n",
       "      <td>683.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fish-and-meat-and-eggs</th>\n",
       "      <td>0.940222</td>\n",
       "      <td>0.929114</td>\n",
       "      <td>0.934635</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fermented-milk-products</th>\n",
       "      <td>0.930609</td>\n",
       "      <td>0.936906</td>\n",
       "      <td>0.933747</td>\n",
       "      <td>5424.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poultries</th>\n",
       "      <td>0.933975</td>\n",
       "      <td>0.932819</td>\n",
       "      <td>0.933397</td>\n",
       "      <td>1372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sauces</th>\n",
       "      <td>0.918065</td>\n",
       "      <td>0.933386</td>\n",
       "      <td>0.925663</td>\n",
       "      <td>3096.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olive-tree-products</th>\n",
       "      <td>0.933401</td>\n",
       "      <td>0.916168</td>\n",
       "      <td>0.924704</td>\n",
       "      <td>668.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         precision    recall   f1score  support\n",
       "cooked-pressed-cheeses    0.969397  0.944737  0.956908    380.0\n",
       "mustards                  0.979548  0.930470  0.954379    489.0\n",
       "prepared-meats            0.941215  0.946119  0.943661   3582.0\n",
       "hams                      0.928870  0.956463  0.942465    735.0\n",
       "honeys                    0.920911  0.957540  0.938868    683.0\n",
       "fish-and-meat-and-eggs    0.940222  0.929114  0.934635    395.0\n",
       "fermented-milk-products   0.930609  0.936906  0.933747   5424.0\n",
       "poultries                 0.933975  0.932819  0.933397   1372.0\n",
       "sauces                    0.918065  0.933386  0.925663   3096.0\n",
       "olive-tree-products       0.933401  0.916168  0.924704    668.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = np.exp(-Dst**2).fillna(0)\n",
    "df_report = evaluation_metrics.get_report(confusion, S)\n",
    "df_report.dropna().sort_values(by=\"f1score\", ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.723461</td>\n",
       "      <td>0.666248</td>\n",
       "      <td>0.693677</td>\n",
       "      <td>177565.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.826741</td>\n",
       "      <td>0.830441</td>\n",
       "      <td>0.828587</td>\n",
       "      <td>177565.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             precision    recall  f1-score   support\n",
       "macro avg     0.723461  0.666248  0.693677  177565.0\n",
       "weighted avg  0.826741  0.830441  0.828587  177565.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics.get_summary(df_report, confusion, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177565.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177565"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.en_tags.apply(len).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/evelyn.trautmann/projects/pydata/evaluate_supervised\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openfoodfact",
   "language": "python",
   "name": "openfoodfact"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "We demo a text classification approach based on an open dataset from https://world.openfoodfacts.org/. The goal of our talk is to categorize food items with various tags, where a particular food item is defined by a product's name, a generic name as well as a brand. For classification, we use facebooks NLP model fasttext, which provides a text classification model based on word embeddings as well as character n-gram embeddings. In a first experiment, we only use a single tag and remove additional ones from each data point. In this case, the evaluation is straight forward. However, since some classes are more closely related than others, we don't want to evaluate predictions in a binary manner as one would typically do. To this end, we implement a similarity concept and a multilabel classification approach. Additionally, we present some applications of a standardized food catalog, for instance search and recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/evelyn.trautmann/projects/pydata/evaluate_supervised\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fasttext import *\n",
    "%matplotlib inline\n",
    "import evaluation_metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import scipy.spatial.distance as sd\n",
    "import sklearn.metrics.pairwise as pw\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "The following classification is based on an open dataset from https://world.openfoodfacts.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_name            324820\n",
       "generic_name             83152\n",
       "brands                  269465\n",
       "categories              329303\n",
       "categories_tags         329303\n",
       "origins                  47351\n",
       "manufacturing_places     73767\n",
       "labels                  118779\n",
       "emb_codes                52104\n",
       "countries               329099\n",
       "main_category           329297\n",
       "en_tags                 329303\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/foodcategories_single_label.csv.zip\", sep = \"\\x01\", compression=\"zip\")\n",
    "df.en_tags = df.en_tags.apply(eval)\n",
    "df = df[df.en_tags.str.len()>0]\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "label, freq = np.unique(np.concatenate(df.en_tags.values), return_counts = True)\n",
    "sr_labels = pd.Series(index=label, data=freq).sort_values()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to classify tags based on product name, generic name and brand. In the first dataset we have a single tag assigned to each data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    329303\n",
       "Name: en_tags, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.en_tags.str.len().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#generate features\n",
    "feature_cols = ['product_name', 'generic_name', 'brands']\n",
    "assert(df[df.en_tags.str.len()==0].shape[0]==0)\n",
    "X = df[feature_cols].fillna(\"\").apply(lambda x: \" \".join(x), axis = 1)\n",
    "y = df.en_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess and split train and test date\n",
    "X = X.str.lower().apply(lambda x: re.sub(r'[^\\w\\s]','',x))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "dftrain = y_train.apply(lambda x: \" \".join([\"__label__\" + y\n",
    "                    for y in x])) + \" \" + X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain_emb = y_train.apply(lambda x: \" \".join(x)) + \" \" + X_train\n",
    "dftrain_emb.to_csv(\n",
    "    \"train_emb.csv\", index = False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = y_test.apply(lambda x: \" \".join([\"__label__\" + y\n",
    "                    for y in x])) + \" \" + X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain.to_csv(\n",
    "    \"train.csv\", index = False, sep=\";\")\n",
    "dftest.to_csv(\n",
    "    \"test.csv\", index = False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification we use fasttext, which can be either executed on command line or "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_singlelabel = train_supervised(\"train.csv\",\n",
    "                autotuneValidationFile = \"test.csv\",\n",
    "                autotuneDuration = 1000)\n",
    "\n",
    "model_singlelabel.save_model(\"model_singlelabel.bin\")\n",
    "# !/Users/evelyn.trautmann/repos/fasttext3/fastText/fasttext supervised \\\n",
    "#     -input \"train.csv\" -output model_singlelabel \\\n",
    "#     -autotune-validation \"test.csv\" -autotune-duration 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim 69\r\n",
      "ws 5\r\n",
      "epoch 18\r\n",
      "minCount 1\r\n",
      "neg 5\r\n",
      "wordNgrams 3\r\n",
      "loss softmax\r\n",
      "model sup\r\n",
      "bucket 10000000\r\n",
      "minn 0\r\n",
      "maxn 0\r\n",
      "lrUpdateRate 100\r\n",
      "t 0.0001\r\n"
     ]
    }
   ],
   "source": [
    "!/Users/evelyn.trautmann/repos/fasttext3/fastText/fasttext dump model_singlelabel.bin args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t108669\r\n",
      "P@1\t0.783\r\n",
      "R@1\t0.783\r\n"
     ]
    }
   ],
   "source": [
    "!/Users/evelyn.trautmann/repos/fasttext3/fastText/fasttext test model_singlelabel.bin test.csv 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model_singlelabel.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_emb = train_unsupervised(\"/Users/evelyn.trautmann/projects/openfood/train_emb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = train_supervised(input=\"/Users/evelyn.trautmann/projects/openfood/train.csv\", \n",
    "#                          autotuneValidationFile=\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108669, 0.7834617048100194, 0.7834617048100194)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_singlelabel.test(\"test.csv\", k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = X_test.to_frame()\n",
    "df_test.columns = [\"feature\"]\n",
    "\n",
    "# determine number of labels\n",
    "df_test = df_test.join(y_test)\n",
    "\n",
    "K = int(df_test.en_tags.str.len().quantile(0.75))\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Label Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"prediction\"] = df_test.feature.apply(lambda x: model_singlelabel.predict(x))\n",
    "\n",
    "df_test[\"label_predicted\"] = df_test.prediction.str[0].str[0].str.replace(\"__label__\",\"\")\n",
    "df_test[\"confidence\"] = df_test.prediction.str[1].str[0]\n",
    "df_test[\"truth\"] = df_test.en_tags.str[0].str.replace(\"__label__\",\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "            alcoholic-beverages       0.82      0.82      0.82      2683\n",
      "                     baby-foods       0.81      0.71      0.76       497\n",
      "                   bee-products       1.00      0.58      0.73        19\n",
      "                          beers       0.00      0.00      0.00         5\n",
      "                      beverages       0.53      0.51      0.52        51\n",
      "             biscuits-and-cakes       0.67      0.52      0.58       875\n",
      "                     breakfasts       0.89      0.88      0.88      5242\n",
      "                          cakes       0.56      0.41      0.47       714\n",
      "                        candies       0.77      0.28      0.41       133\n",
      "                  canned-fishes       0.76      0.75      0.75       907\n",
      "                   canned-foods       0.37      0.12      0.18       115\n",
      "       canned-plant-based-foods       0.53      0.41      0.47       138\n",
      "              carbonated-drinks       0.66      0.60      0.63       356\n",
      "                       chickens       0.91      0.93      0.92      1243\n",
      "                chips-and-fries       0.56      0.26      0.36        68\n",
      "             chocolate-biscuits       0.72      0.56      0.63       830\n",
      "                     chocolates       0.31      0.08      0.13       110\n",
      "                     condiments       0.73      0.58      0.64       472\n",
      "                        dairies       0.69      0.62      0.65      1366\n",
      "                       desserts       0.71      0.70      0.70      1557\n",
      "            dietary-supplements       0.73      0.70      0.71       567\n",
      "                 dried-products       0.63      0.59      0.61       452\n",
      "               farming-products       0.95      0.94      0.94       509\n",
      "                           fats       0.50      0.24      0.32       567\n",
      "                fermented-foods       0.77      0.80      0.79      4356\n",
      "        fermented-milk-products       0.83      0.83      0.83      4737\n",
      "         fish-and-meat-and-eggs       0.96      0.95      0.95       635\n",
      "                    fresh-foods       0.47      0.28      0.35       708\n",
      "        fresh-plant-based-foods       0.59      0.54      0.56       710\n",
      "                   frozen-foods       0.73      0.62      0.67       728\n",
      "       frozen-plant-based-foods       0.66      0.65      0.65       537\n",
      "        frozen-ready-made-meals       0.36      0.25      0.29       328\n",
      "             fruits-based-foods       0.79      0.64      0.71       144\n",
      "                      groceries       0.58      0.31      0.41       131\n",
      "                           hams       0.90      0.94      0.92      1303\n",
      "                  hot-beverages       0.00      0.00      0.00        35\n",
      "                     ice-creams       0.83      0.85      0.84      1001\n",
      "                   legume-seeds       0.82      0.78      0.80       820\n",
      "                        legumes       0.00      0.00      0.00         9\n",
      "     legumes-and-their-products       0.86      0.68      0.76       125\n",
      "                          meals       0.71      0.75      0.73      3779\n",
      "                meals-with-fish       0.82      0.73      0.77       372\n",
      "            meat-based-products       0.79      0.81      0.80      2262\n",
      "                          meats       0.82      0.82      0.82      1884\n",
      "                microwave-meals       0.31      0.04      0.07       119\n",
      "                milk-chocolates       0.00      0.00      0.00         1\n",
      "                milk-substitute       0.00      0.00      0.00         8\n",
      "                          milks       0.85      0.81      0.83      1496\n",
      "        non-alcoholic-beverages       0.49      0.44      0.46      1959\n",
      "                           nuts       0.85      0.80      0.82      1017\n",
      "            olive-tree-products       0.86      0.92      0.89      1067\n",
      "                         olives       0.91      0.94      0.93       569\n",
      "                       pastries       0.77      0.74      0.75       786\n",
      "                        pickles       0.88      0.74      0.80       343\n",
      "          plant-based-beverages       0.00      0.00      0.00         2\n",
      "              plant-based-foods       0.78      0.88      0.83     19831\n",
      "plant-based-foods-and-beverages       0.72      0.81      0.76      4589\n",
      "                      poultries       0.90      0.89      0.89       638\n",
      "                 prepared-meats       0.88      0.89      0.88      3371\n",
      "            prepared-vegetables       0.00      0.00      0.00         6\n",
      "             refrigerated-foods       0.00      0.00      0.00        52\n",
      "                         salads       0.00      0.00      0.00        58\n",
      "                 salted-spreads       0.00      0.00      0.00         3\n",
      "                   salty-snacks       0.84      0.76      0.80       865\n",
      "                         sauces       0.93      0.93      0.93      4990\n",
      "                       sausages       0.79      0.41      0.54        37\n",
      "                        seafood       0.84      0.85      0.84      2549\n",
      "                  smoked-fishes       0.00      0.00      0.00         9\n",
      "                         snacks       0.79      0.84      0.82     11678\n",
      "                          soups       0.73      0.64      0.68       452\n",
      "                        spreads       0.80      0.75      0.77      1215\n",
      "                   sweet-snacks       0.69      0.60      0.64      1012\n",
      "            sweetened-beverages       0.61      0.59      0.60      2167\n",
      "                     sweeteners       0.89      0.84      0.86       789\n",
      "                         syrups       0.59      0.35      0.44       121\n",
      "                           teas       0.00      0.00      0.00        20\n",
      "          unsweetened-beverages       0.47      0.30      0.37      1716\n",
      "                 vegetable-fats       0.00      0.00      0.00        26\n",
      "         vegetables-based-foods       0.70      0.59      0.64       582\n",
      "              wines-from-france       0.65      0.54      0.59       447\n",
      "\n",
      "                      micro avg       0.78      0.78      0.78    108670\n",
      "                      macro avg       0.61      0.54      0.56    108670\n",
      "                   weighted avg       0.78      0.78      0.78    108670\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(df_test.truth, df_test.label_predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# assertion no empty tags\n",
    "assert(len(df_test.en_tags[df_test.en_tags.str.len()==0])==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the model is predicting other than the ground truth but still makes reasonable class assignments. To distinguish the reasonable assignments from the actually wrong classifications we introduce similarities between classes to count them into the accurate predicftions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example\n",
    "Consider followin common products\n",
    "spaghetti bolognese, linguine bolognese, chicken biryani\n",
    "Given that the first two are pretty similar and the latter very different, a possible similarity matrix S could look like\n",
    "\n",
    "\n",
    "\n",
    "|Labels | spaghetti bolognese | linguine bolognese |chicken biryani|\n",
    "|---------|:------------------|:-------------------|:--------------|\n",
    "|spaghetti bolognese | 1 | 0.9 | 0 |\n",
    "| linguine bolognese | 0.9 | 1 | 0 |\n",
    "| chicken biryani | 0 | 0 | 1 |\n",
    "\n",
    "\n",
    "If we want to include now similarity into calculation of precision and recall, we have the nominator containing not only\n",
    "\n",
    "#[ Actual = spaghetti bolognese, Predicted = spaghetti bolognese ]\n",
    "\n",
    "but\n",
    "\n",
    "#[ Actual = spaghetti bolognese, Predicted = spaghetti bolognese ] * 1 + \n",
    "#[ Actual = spaghetti bolognese, Predicted = linguine bolognese ] * 0.9.\n",
    "\n",
    "Hence diagonal entries of confusion matrix \n",
    "\n",
    "$$ C_{ii} = \\#[Actual=i,Predicted=i]$$\n",
    "\n",
    "become \n",
    "\n",
    "$$ C_{ii} = \\sum_j \\#[Actual=i,Predicted=j]* S_{ij} $$\n",
    "\n",
    "That means, we count in all similar predictions weighted by degree of similatity.\n",
    "Technically that means we take the diagonal entris of\n",
    "\n",
    "$$\\hat{C}=C∗S\\hat{C} = C * S \\hat{C}=C∗S$$\n",
    "\n",
    "\n",
    "Where * denotes matrix product. Denominator remains the same: Row sum in case of precision, column sum in case of recall. Here we don't weight by similar entries since for denominator only the exact number of Actuals (resp. Predicted ) counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute diffecence sets\n",
      "compute intersectiosn\n",
      "compute onehot vectors\n",
      "CPU times: user 7min 43s, sys: 11 s, total: 7min 54s\n",
      "Wall time: 7min 54s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "truth = [\"truth\"]\n",
    "predictions = [\"label_predicted\"]\n",
    "classes = list(set(np.concatenate(df_test[predictions + truth].apply(tuple).apply(list).values)))\n",
    "\n",
    "%time confusion = evaluation_metrics.get_confusion(df_test, classes, K, truth, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:56: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'numpy.str_' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-f57b7ed86c48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDst\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mDst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mDst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_datetimelike_v_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/ops.pyx\u001b[0m in \u001b[0;36mpandas._libs.ops.scalar_compare\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'numpy.str_' and 'float'"
     ]
    }
   ],
   "source": [
    "class_vecs = pd.Series({cl:model_emb.get_sentence_vector(cl) for cl in classes})\n",
    "\n",
    "Dst = class_vecs.apply(lambda x: class_vecs.apply(lambda y: sd.euclidean(x,y)))\n",
    "\n",
    "mask = Dst > 0.5\n",
    "Dst[mask]=np.nan\n",
    "Dst.apply(np.argmax)[Dst.apply(np.argmax)>0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    80\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dst[mask].count().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.exp(-Dst**2).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fish-and-meat-and-eggs</th>\n",
       "      <td>0.949606</td>\n",
       "      <td>0.955626</td>\n",
       "      <td>0.952607</td>\n",
       "      <td>631.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>farming-products</th>\n",
       "      <td>0.941061</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>0.949455</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sauces</th>\n",
       "      <td>0.934431</td>\n",
       "      <td>0.928431</td>\n",
       "      <td>0.931421</td>\n",
       "      <td>5024.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olives</th>\n",
       "      <td>0.943761</td>\n",
       "      <td>0.914821</td>\n",
       "      <td>0.929066</td>\n",
       "      <td>587.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chickens</th>\n",
       "      <td>0.938662</td>\n",
       "      <td>0.911389</td>\n",
       "      <td>0.924825</td>\n",
       "      <td>1282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fermented-milk-products</th>\n",
       "      <td>0.924838</td>\n",
       "      <td>0.916728</td>\n",
       "      <td>0.920765</td>\n",
       "      <td>4731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hams</th>\n",
       "      <td>0.932464</td>\n",
       "      <td>0.906040</td>\n",
       "      <td>0.919062</td>\n",
       "      <td>1341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poultries</th>\n",
       "      <td>0.895613</td>\n",
       "      <td>0.913071</td>\n",
       "      <td>0.904258</td>\n",
       "      <td>624.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olive-tree-products</th>\n",
       "      <td>0.920337</td>\n",
       "      <td>0.858392</td>\n",
       "      <td>0.888286</td>\n",
       "      <td>1144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breakfasts</th>\n",
       "      <td>0.874285</td>\n",
       "      <td>0.895817</td>\n",
       "      <td>0.884920</td>\n",
       "      <td>5116.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         precision    recall   f1score  support\n",
       "fish-and-meat-and-eggs    0.949606  0.955626  0.952607    631.0\n",
       "farming-products          0.941061  0.958000  0.949455    500.0\n",
       "sauces                    0.934431  0.928431  0.931421   5024.0\n",
       "olives                    0.943761  0.914821  0.929066    587.0\n",
       "chickens                  0.938662  0.911389  0.924825   1282.0\n",
       "fermented-milk-products   0.924838  0.916728  0.920765   4731.0\n",
       "hams                      0.932464  0.906040  0.919062   1341.0\n",
       "poultries                 0.895613  0.913071  0.904258    624.0\n",
       "olive-tree-products       0.920337  0.858392  0.888286   1144.0\n",
       "breakfasts                0.874285  0.895817  0.884920   5116.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_report = evaluation_metrics.get_report(confusion, S)\n",
    "df_report.dropna().sort_values(by=\"f1score\", ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.803342</td>\n",
       "      <td>0.803342</td>\n",
       "      <td>0.803342</td>\n",
       "      <td>108670.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.639211</td>\n",
       "      <td>0.730071</td>\n",
       "      <td>0.681627</td>\n",
       "      <td>108670.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.820437</td>\n",
       "      <td>0.803342</td>\n",
       "      <td>0.811799</td>\n",
       "      <td>108670.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             precision    recall  f1-score   support\n",
       "micro avg     0.803342  0.803342  0.803342  108670.0\n",
       "macro avg     0.639211  0.730071  0.681627  108670.0\n",
       "weighted avg  0.820437  0.803342  0.811799  108670.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics.get_summary(df_report, confusion, S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilabel Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df = pd.read_csv(\"data/foodcategories_3labels.csv.zip\", sep = \"\\x01\", compression=\"zip\")\n",
    "df.en_tags = df.en_tags.apply(eval)\n",
    "df = df[df.en_tags.str.len()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.en_tags\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "dftrain = y_train.apply(lambda x: \" \".join([\"__label__\" + y\n",
    "                    for y in x])) + \" \" + X_train\n",
    "dftest = y_test.apply(lambda x: \" \".join([\"__label__\" + y\n",
    "                    for y in x])) + \" \" + X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain.to_csv(\n",
    "    \"train_3label.csv\", index = False, sep=\";\")\n",
    "dftest.to_csv(\n",
    "    \"test3label.csv\", index = False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_supervised??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3label = train_supervised(\"train_3label.csv\",\n",
    "                autotuneValidationFile = \"test.csv\",\n",
    "                autotuneDuration = 1000)\n",
    "\n",
    "# !/Users/evelyn.trautmann/repos/fasttext3/fastText/fasttext supervised \\\n",
    "#     -input \"train_3label.csv\" -output model_3label \\\n",
    "#     -autotune-validation \"test3label.csv\" -autotune-duration 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3label.save_model(\"model_3label.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model_3label.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let \\{$T_1^{(1)}, ...,T_M^{(1)}$\\},...,\\{$T_1^{(N)}, ...,T_M^{(N)}$\\} be our ground truth, \n",
    "\\{$P_1^{(1)}, ...,P_M^{(1)}$\\},...,\\{$P_1^{(N)}, ...,P_M^{(N)}$\\} the prediction.\n",
    "\n",
    "on diagonal we count the events of truth matching prediction\n",
    "\n",
    "$\\sum_{i=1}^N |\\{T_1^{(i)}, ...,T_M^{(i)}\\}\\cap \\{P_1^{(i)}, ...,P_M^{(i)}\\}|$\n",
    "\n",
    "so for each diagonal entry we count over all data points (N) and all predictions (M) the total amount when truth is matching prediction.\n",
    "\n",
    "$C_{kk} =\\sum_{i=1}^N \\sum_{m=1}^M \\chi{1}\\{T_m^{(i)}=k,P_m^{(i)}=k\\} $\n",
    "\n",
    "in contrast on off-diagonal we count all events where truth was not covered by prediction.\n",
    "For the off-diagonal we take only the difference sets into account. If truth for data point i was for example {fish, curry, rice-dish} and prediction was {fish, curry, soup }, we only count \n",
    "$T^i$ = {rice_dish} and $P^i$ = {soup} for the off-daigonal. Formally we do the following transformation:\n",
    "\n",
    "$\\{\\tilde{T}_m^{(i)}\\}_{q=1,..M1} = \\{T_m^{(i)}\\}_{m=1,..M}\\setminus \\{P_m^{(i)}\\}_{m=1,..M}$ \n",
    "\n",
    "$\\{\\tilde{P}_m^{(i)}\\}_{p=1,..M2} = \\{P_m^{(i)}\\}_{m=1,..M}\\setminus \\{T_m^{(i)}\\}_{m=1,..M}$\n",
    "\n",
    "Eventually we count all events of the ground truth that were not captured in predictions, which results in\n",
    "\n",
    "$C_{kl} =\\sum_{i=1}^N \\sum_{m1=1}^{M1} \\sum_{m2=1}^{M2}\n",
    "\\frac{1}{M1}\\chi{1}\\{\\tilde{T}_{m1}^{(i)}=k,\\tilde{P}_{m2}^{(i)}=l\\} $\n",
    "\n",
    "Once we have computed a multi-class - multi-label confusion matrix the classification report is straight forward.\n",
    "\n",
    "Precision for class k is computed as\n",
    "\n",
    "$Pr_k=\\frac{C_{kk}}{\\sum_j C_{kj}}$\n",
    "\n",
    "and Recall\n",
    "\n",
    "$R_k=\\frac{C_{kk}}{\\sum_j C_{jk}}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = X_test.to_frame()\n",
    "df_test.columns = [\"feature\"]\n",
    "\n",
    "# determine number of labels\n",
    "df_test = df_test.join(y_test)\n",
    "\n",
    "K = int(df_test.en_tags.str.len().quantile(0.75))\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"prediction\"] = df_test.feature.apply(lambda x: model_3label.predict(x, k=K))\n",
    "\n",
    "for k in range(K):\n",
    "    df_test[\"label_predicted%i\" %k] = df_test.prediction.str[0].str[k].str.replace(\"__label__\",\"\")\n",
    "    df_test[\"confidence%i\" %k] = df_test.prediction.str[1].str[k]\n",
    "    df_test[\"truth%i\" %k] = df_test.en_tags.str[k].str.replace(\"__label__\",\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = list()\n",
    "predictions = list()\n",
    "for k in range(int(K)):\n",
    "    truth.append(\"truth%i\" %k)\n",
    "    predictions.append(\"label_predicted%i\" %k)\n",
    "classes = list(set(np.concatenate(df_test[predictions + truth].apply(tuple).apply(list).values)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 53s, sys: 10.9 s, total: 8min 4s\n",
      "Wall time: 8min 5s\n"
     ]
    }
   ],
   "source": [
    "%time confusion = evaluation_metrics.get_confusion(df_test, classes, K, truth, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cooked-pressed-cheeses</th>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.981346</td>\n",
       "      <td>0.962992</td>\n",
       "      <td>616.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prepared-meats</th>\n",
       "      <td>0.952300</td>\n",
       "      <td>0.943407</td>\n",
       "      <td>0.947832</td>\n",
       "      <td>5925.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mustards</th>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.977433</td>\n",
       "      <td>0.944142</td>\n",
       "      <td>709.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hams</th>\n",
       "      <td>0.940639</td>\n",
       "      <td>0.941954</td>\n",
       "      <td>0.941296</td>\n",
       "      <td>1312.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>farming-products</th>\n",
       "      <td>0.936293</td>\n",
       "      <td>0.945726</td>\n",
       "      <td>0.940986</td>\n",
       "      <td>512.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>honeys</th>\n",
       "      <td>0.960664</td>\n",
       "      <td>0.921851</td>\n",
       "      <td>0.940858</td>\n",
       "      <td>1192.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fermented-milk-products</th>\n",
       "      <td>0.940730</td>\n",
       "      <td>0.937072</td>\n",
       "      <td>0.938898</td>\n",
       "      <td>9129.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fish-and-meat-and-eggs</th>\n",
       "      <td>0.957547</td>\n",
       "      <td>0.917629</td>\n",
       "      <td>0.937163</td>\n",
       "      <td>663.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meats</th>\n",
       "      <td>0.963753</td>\n",
       "      <td>0.908365</td>\n",
       "      <td>0.935240</td>\n",
       "      <td>9396.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poultries</th>\n",
       "      <td>0.948444</td>\n",
       "      <td>0.919695</td>\n",
       "      <td>0.933849</td>\n",
       "      <td>2320.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         precision    recall   f1score      support\n",
       "cooked-pressed-cheeses    0.945312  0.981346  0.962992   616.500000\n",
       "prepared-meats            0.952300  0.943407  0.947832  5925.333333\n",
       "mustards                  0.913043  0.977433  0.944142   709.000000\n",
       "hams                      0.940639  0.941954  0.941296  1312.166667\n",
       "farming-products          0.936293  0.945726  0.940986   512.833333\n",
       "honeys                    0.960664  0.921851  0.940858  1192.166667\n",
       "fermented-milk-products   0.940730  0.937072  0.938898  9129.500000\n",
       "fish-and-meat-and-eggs    0.957547  0.917629  0.937163   663.666667\n",
       "meats                     0.963753  0.908365  0.935240  9396.000000\n",
       "poultries                 0.948444  0.919695  0.933849  2320.333333"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report = evaluation_metrics.get_report(confusion)\n",
    "df_report.dropna().sort_values(by=\"f1score\", ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.829391</td>\n",
       "      <td>0.829391</td>\n",
       "      <td>0.829391</td>\n",
       "      <td>293144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.704026</td>\n",
       "      <td>0.788582</td>\n",
       "      <td>0.743909</td>\n",
       "      <td>293144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.840394</td>\n",
       "      <td>0.829391</td>\n",
       "      <td>0.834856</td>\n",
       "      <td>293144.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             precision    recall  f1-score   support\n",
       "micro avg     0.829391  0.829391  0.829391  293144.0\n",
       "macro avg     0.704026  0.788582  0.743909  293144.0\n",
       "weighted avg  0.840394  0.829391  0.834856  293144.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics.get_summary(df_report, confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Multilabel Classification with Near Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tomato-sauces                                         tomato-sauces\n",
       "meals-with-meat                                     meals-with-meat\n",
       "milks                                                         milks\n",
       "sweeteners                                               sweeteners\n",
       "pastries                                                   pastries\n",
       "baby-foods                                               baby-foods\n",
       "milk-substitute                                     milk-substitute\n",
       "legume-seeds                                           legume-seeds\n",
       "potato-crisps                                         potato-crisps\n",
       "dairies                                                     dairies\n",
       "fats                                                           fats\n",
       "fishes                                                      seafood\n",
       "fruits-based-foods                               fruits-based-foods\n",
       "dairy-desserts                                       dairy-desserts\n",
       "confectioneries                                     confectioneries\n",
       "teas                                                           teas\n",
       "seeds                                                         seeds\n",
       "breads                                                       breads\n",
       "snacks                                                       snacks\n",
       "viennoiseries                                         viennoiseries\n",
       "bars                                                           bars\n",
       "olives                                                       olives\n",
       "cereal-grains                                         cereal-grains\n",
       "canned-foods                                           canned-foods\n",
       "meals                                                         meals\n",
       "poultries                                                  chickens\n",
       "chocolate-biscuits                               chocolate-biscuits\n",
       "syrups                                                       syrups\n",
       "salmons                                                     salmons\n",
       "frozen-foods                                           frozen-foods\n",
       "                                                 ...               \n",
       "artificially-sweetened-beverages                sweetened-beverages\n",
       "cooked-pressed-cheeses                       cooked-pressed-cheeses\n",
       "canned-fishes                                         canned-fishes\n",
       "salty-snacks                                           salty-snacks\n",
       "hams                                                           hams\n",
       "ice-creams                                          frozen-desserts\n",
       "appetizers                                               appetizers\n",
       "smoked-fishes                                         smoked-fishes\n",
       "cow-cheeses                                             cow-cheeses\n",
       "alcoholic-beverages                             alcoholic-beverages\n",
       "milk-chocolates                                          chocolates\n",
       "vegetable-fats                                       vegetable-fats\n",
       "legumes                                                     legumes\n",
       "french-cheeses                                       french-cheeses\n",
       "frozen-plant-based-foods                   frozen-plant-based-foods\n",
       "fresh-foods                                             fresh-foods\n",
       "canned-plant-based-foods                    dried-plant-based-foods\n",
       "plant-based-pickles                             plant-based-pickles\n",
       "unsweetened-beverages                           sweetened-beverages\n",
       "bee-products                                           bee-products\n",
       "meats                                                         meats\n",
       "sauces                                                    groceries\n",
       "fresh-plant-based-foods                     fresh-plant-based-foods\n",
       "wines                                             wines-from-france\n",
       "frozen-desserts                                          ice-creams\n",
       "farming-products                                   farming-products\n",
       "plant-based-foods                   plant-based-foods-and-beverages\n",
       "chips-and-fries                                     chips-and-fries\n",
       "chicken-breasts                                            chickens\n",
       "sweet-spreads                                         sweet-spreads\n",
       "Length: 136, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_vecs = pd.Series({cl:model_emb.get_sentence_vector(cl) for cl in classes})\n",
    "\n",
    "Dst = class_vecs.apply(lambda x: class_vecs.apply(lambda y: sd.euclidean(x,y)))\n",
    "\n",
    "mask = Dst > 0.5\n",
    "Dst[mask]=np.nan\n",
    "# show entries with highes distance <= 0.5 for each class\n",
    "Dst.apply(np.argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cooked-pressed-cheeses</th>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.981346</td>\n",
       "      <td>0.962992</td>\n",
       "      <td>616.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prepared-meats</th>\n",
       "      <td>0.952300</td>\n",
       "      <td>0.943407</td>\n",
       "      <td>0.947832</td>\n",
       "      <td>5925.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mustards</th>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.977433</td>\n",
       "      <td>0.944142</td>\n",
       "      <td>709.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hams</th>\n",
       "      <td>0.940639</td>\n",
       "      <td>0.941954</td>\n",
       "      <td>0.941296</td>\n",
       "      <td>1312.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>farming-products</th>\n",
       "      <td>0.936293</td>\n",
       "      <td>0.945726</td>\n",
       "      <td>0.940986</td>\n",
       "      <td>512.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>honeys</th>\n",
       "      <td>0.960664</td>\n",
       "      <td>0.921851</td>\n",
       "      <td>0.940858</td>\n",
       "      <td>1192.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fermented-milk-products</th>\n",
       "      <td>0.940979</td>\n",
       "      <td>0.937203</td>\n",
       "      <td>0.939087</td>\n",
       "      <td>9129.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fish-and-meat-and-eggs</th>\n",
       "      <td>0.957547</td>\n",
       "      <td>0.917629</td>\n",
       "      <td>0.937163</td>\n",
       "      <td>663.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meats</th>\n",
       "      <td>0.963753</td>\n",
       "      <td>0.908365</td>\n",
       "      <td>0.935240</td>\n",
       "      <td>9396.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poultries</th>\n",
       "      <td>0.948444</td>\n",
       "      <td>0.921113</td>\n",
       "      <td>0.934579</td>\n",
       "      <td>2320.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         precision    recall   f1score      support\n",
       "cooked-pressed-cheeses    0.945312  0.981346  0.962992   616.500000\n",
       "prepared-meats            0.952300  0.943407  0.947832  5925.333333\n",
       "mustards                  0.913043  0.977433  0.944142   709.000000\n",
       "hams                      0.940639  0.941954  0.941296  1312.166667\n",
       "farming-products          0.936293  0.945726  0.940986   512.833333\n",
       "honeys                    0.960664  0.921851  0.940858  1192.166667\n",
       "fermented-milk-products   0.940979  0.937203  0.939087  9129.500000\n",
       "fish-and-meat-and-eggs    0.957547  0.917629  0.937163   663.666667\n",
       "meats                     0.963753  0.908365  0.935240  9396.000000\n",
       "poultries                 0.948444  0.921113  0.934579  2320.333333"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = np.exp(-Dst**2).fillna(0)\n",
    "df_report = evaluation_metrics.get_report(confusion, S)\n",
    "df_report.dropna().sort_values(by=\"f1score\", ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.83289</td>\n",
       "      <td>0.83289</td>\n",
       "      <td>0.83289</td>\n",
       "      <td>293144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.71257</td>\n",
       "      <td>0.795681</td>\n",
       "      <td>0.751836</td>\n",
       "      <td>293144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.842982</td>\n",
       "      <td>0.83289</td>\n",
       "      <td>0.837906</td>\n",
       "      <td>293144.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             precision    recall  f1-score   support\n",
       "micro avg      0.83289   0.83289   0.83289  293144.0\n",
       "macro avg      0.71257  0.795681  0.751836  293144.0\n",
       "weighted avg  0.842982   0.83289  0.837906  293144.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics.get_summary(df_report, confusion, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openfoodfact",
   "language": "python",
   "name": "openfoodfact"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
